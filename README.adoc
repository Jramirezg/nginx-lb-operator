= NGINX Controller Operator
:showtitle:
:toc: left

== Operator SDK
This Operator was built with the operator SDK. Follow these install instructions...

https://sdk.operatorframework.io/docs/install-operator-sdk/[https://sdk.operatorframework.io/docs/install-operator-sdk/]

== Codeready Containers Setup

=== Trust CRC Repo

First trust make docker trust the certificate from your CRC repo. Get the cert with:

----
oc extract secret/router-ca --keys=tls.crt -n openshift-ingress-operator --confirm --to=-
----

On Debian/Ubuntu you can make the OS trust the Cert by adding it to you ca-certificates

----
oc extract secret/router-ca --keys=tls.crt -n openshift-ingress-operator --confirm --to=- | sudo tee /usr/local/share/ca-certificates/crc-router.crt
sudo update-ca-certificates
----

Then login to the repo

----
docker login -p $(oc whoami -t) -u unused default-route-openshift-image-registry.apps-crc.testing
----

== Build the Operator 

These instructions assume you are using the OCP 4.x image-repository in CRC. Change the image name if you're deploying
onto a real OCP environment

=== Store image in same project

We need the OCP project to exist first, else we can't upload images for it.
----
oc new-project lb-nginx-com
----

build and push to our new project.

----
export IMAGE=default-route-openshift-image-registry.apps-crc.testing/lb-nginx-com/nginx-lb-operator:latest
operator-sdk build $IMAGE
docker push $IMAGE
----

=== Store image in different project (eg default)

Alternatively you can push to the default project (or any other project) as long as your project has access.

Enable cross namespace repo access with:

----
oc policy add-role-to-group registry-viewer system:serviceaccounts:<consumer> --namespace=<publisher>
----

Eg:

----
oc policy add-role-to-group registry-viewer system:serviceaccounts:lb-nginx-com --namespace=default
----

Then push to default (or other) project...

----
export IMAGE=default-route-openshift-image-registry.apps-crc.testing/default/nginx-lb-operator:latest
operator-sdk build $IMAGE
docker push $IMAGE
----

You can ofcourse build and push to an extneral docker registry too ;-)

== Install the CRDs

----
oc create -f deploy/crds/lb.nginx.com_controllers_crd.yaml
oc create -f deploy/crds/lb.nginx.com_applications_crd.yaml
oc create -f deploy/crds/lb.nginx.com_components_crd.yaml
oc create -f deploy/crds/lb.nginx.com_gateways_crd.yaml
----

== Deploy the Operator

The Operator is namespace-scoped, so each project needs to run it's own operator. It might make more
sense to deploy as a cluster-scoped operator, but for now it per namespace.

Check that you're on the correct project, and then deploy the operator

----
export IMAGE=image-registry.openshift-image-registry.svc:5000/default/nginx-lb-operator:latest
sed -e "s|REPLACE_IMAGE|${IMAGE}|g" deploy/operator.yaml > deploy/operator-for-reals.yaml
oc create -f deploy/service_account.yaml
oc create -f deploy/role.yaml
oc create -f deploy/role_binding.yaml
oc create -f deploy/operator-for-reals.yaml
----

== Managing NGINX Configs

After deploying the operator it will start watching for new instances of the CRDs. There are
currently 5 CRDs, and 4 of them are watched.

.CRDs
|===
| CRD | Description | Watched

| lb.nginx.com_controllers
| Controller Configuration, Includes FQDN, Auth details, and the Environment to use.
| No

| lb.nginx.com_applications
| The Application as represented in NGINX Controller
| Yes

| lb.nginx.com_gateways
| A Service gateway, The NGINX instances on which components will be deployed
| Yes

| lb.nginx.com_components
| The component is deployed into and application on a gateway
| Yes

| lb.nginx.com_certificates
| Coming Soon
| Yes
|===

The controller needs to be configured first.

=== Controller CRD

The controller CRD take a user_email, FQDN, and Environment. It also needs a password stored in a Kubernetes Secret

Such as: 

[source,yaml]
----
kind: Secret
apiVersion: v1
metadata:
  name: dev-controller
data:
  user_password: bm90cmVhbGx5bXlwYXNzd29yZAo=
type: Opaque
----

The secret will be updated by the operator with an oath_token and a login_timestamp. The Operator will reuse the oath token for
30 minutes, after which it will perform a new login.

A controller object using the above secret would look like this:

[source,yaml]
----
apiVersion: lb.nginx.com/v1alpha1
kind: Controller
metadata:
  name: dev-controller
spec:
  user_email: "admin@nginx.com"
  secret: "dev-controller"
  fqdn: "ctrl.nginx.lab"
  environment: "ocp-dev-1"
  validate_certs: true
----

The user account and the environment should already exist on the controller. All Applications, Gateways, Components, and Certificates
will reference a controller object by name and be deployed into the environment specified.

=== Application CRD

The Application is a simple object, but it groups the components and helps with analytics visualisation

[source,yaml]
----
apiVersion: lb.nginx.com/v1alpha1
kind: Application
metadata:
  name: my-application
spec:
  controller: "dev-controller"
  displayName: "My Kubernetes Application"
  description: "An application deployed in Kubernetes"
----

=== Gateway CRD

The Gateways object takes a `desiredState` whch is sent to controller as is, so you can enable
any features exposed in the Controller API. Check your controller API for more information.

[source,yaml]
----
apiVersion: lb.nginx.com/v1alpha1
kind: Gateway
metadata:
  name: my-gateway
spec:
  controller: "dev-controller"
  displayName: "My OCP Gateway"
  description: "A gateway deployed by Kubernetes"
  desiredState:
    ingress:
      placement:
        instancerefs:
          - ref: /infrastructure/locations/unspecified/instances/6
      uris:
        'http://www.uk.nginx.lab': {}
        'http://www.foo.com': {}
----

=== Component CRD

The Component object also takes a `desiredState`, but the operator expects to configure both the `ingress->gatewayRefs` 
using the `gateway` provided, and the `backend->workloadGroups->group` using the pods or NodePorts found in the `ingress`
setting. The workload `uris` are built using `workload.scheme` and `workload.path`

[source,yaml]
----
apiVersion: lb.nginx.com/v1alpha1
kind: Component
metadata:
  name: my-component
spec:
  controller: "dev-controller"
  application: "my-application"
  ingress: "my-nginx-ingress-controller"
  gateway: "my-gateway"
  workload:
    scheme: "http"
    path: "/"
    targetPort: 443
    crcOverride: 192.168.130.11
  displayName: "My Component"
  description: "A component deployed by Kubernetes"
  desiredState:
    backend:
      monitoring:
        response:
          status:
            match: true
            range:
              endCode: 302
              startCode: 200
        uri: /
      workloadGroups:
        # group uris will be populated from "ingress" pods or nodeports
        group:
          loadBalancingMethod:
            type: ROUND_ROBIN
    # ingress gatewayRefs will be populated from "gateway"
    ingress:
      uris:
        /: {}
----

The above would result in a `desiredState` similar to:

[source,json]
----
  "desiredState": {
    "ingress": {
      "gatewayRefs": [
        {
          "ref": "/services/environments/ocp-dev-1/gateways/<project>.my-gateway"
        }
      ],
      "uris": {
        "/": {}
      }
    },
    "backend": {
      "workloadGroups": {
        "group": {
          "loadBalancingMethod": {
            "type": "ROUND_ROBIN"
          },
          "uris": {
            "http://<k8s-node-ip>:<nodeport>/": { }
          }
        }
      },
      "monitoring": {
        "uri": "/",
        "response": {
          "status": {
            "range": {
              "endCode": 302,
              "startCode": 200
            },
            "match": true
          }
        }
      }
    }
  }
----

=== Certificate CRD

TODO TODO

